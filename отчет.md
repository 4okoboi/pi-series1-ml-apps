# Отчёт по подзадачам ML‑приложений
Репозиторий - https://github.com/4okoboi/pi-series1-ml-apps
## 1) Классификация текста (Sentiment Analysis) — `1-text/`

- Выбранные инструменты: `transformers` (HuggingFace) и `pipeline('sentiment-analysis')`.
- Модели: по умолчанию `distilbert/distilbert-base-uncased-finetuned-sst-2-english`, для русского — `blanchefort/rubert-base-cased-sentiment`.

### Преимущества выбранной библиотеки
- Высокоуровневый API (`pipeline`): быстрый старт.
- Большой выбор предобученных моделей.
- Поддержка CPU/GPU, удобная интеграция в прод.
- Хорошее качество из коробки по популярным задачам.

### Принцип работы модели и причины выбора
- Модель семейства BERT/DistilBERT — трансформер с механизмом самовнимания, обученный для классификации сентимента (двухклассовой SST‑2) на английском; для русского — предобученный RuBERT, дообученный под сентимент.
- Причины выбора: готовые веса, высокая точность для коротких текстов, нет надобности в обучении.

### Особенности реализации алгоритма
- Минимальный код: инициализация `pipeline(task='sentiment-analysis', model=...)` и единичный инференс на тексте.
- Как работает pipeline: токенизация → трансформер → логиты → softmax → метка и вероятность (`label`, `score`).

### Эффективность
- Для коротких фраз задержка на CPU — <100 миллисекунд; на GPU работает быстрее.
- Память/время умеренные; для прод‑нагрузок можно держать `pipeline` и модель в оперативе

---

## 2) Транскрибация аудио — `2-audio/`

- Выбранные инструменты: `openai-whisper` + `torch` (PyTorch).
- Модель: `whisper.small` (многоязычная).

### Преимущества выбранной библиотеки
- Многоязычная устойчивая модель, хорошо работает «из коробки» на шумных данных.
- Простое API загрузки/инференса, поддержка CPU/GPU, автоматическая сегментация и таймкоды.
- Гибкие опции (язык, режим перевода/транскрибации (в решении задачи использована только транскрибация), fp16 на CUDA).

### Принцип работы модели и причины выбора
- Whisper — энкодер‑декодер трансформер: вход — лог‑мел‑спектрограмма; декодер автогрессивно порождает текстовые токены.
- Обучен на очень большом корпусе аудио‑текста, что даёт устойчивость к акцентам и шумам.
- Выбор варианта `small`: хороший компромисс между точностью и скоростью; подходит для CPU, а на GPU даёт низкую задержку с fp16.

### Особенности реализации алгоритма
- CLI через `argparse`: `--input`, `--output`, `--language {en,ru}`, форматы `--txt/--json`.
- Выбор устройства: `cuda` при наличии, иначе `cpu`; `fp16=True` только на CUDA.
- Загрузка модели `whisper.load_model('small', device=...)`; инференс `model.transcribe(audio=..., task='transcribe', language=...)`.
- Сохранение результата в `.txt` и/или `.json` (текст + сегменты); вывод в консоль.

### Эффективность
- На CPU `small` даёт приемлемое время для коротких/средних файлов; на GPU — существенно быстрее (fp16).
- Время линейно растёт с длительностью аудио и зависит от размера модели.
- Для длительных файлов рекомендуется GPU; также можно регулировать параметры декодирования (beam size и пр.) для компромисса скорость/качество.
- Требуется установленный `ffmpeg` для корректной загрузки медиа.

---

## 3) Zero‑shot классификация изображений — `3-image/`

- Выбранные инструменты: `transformers` `pipeline('zero-shot-image-classification')` + `Pillow`.
- Модель: `openai/clip-vit-large-patch14`.

### Преимущества выбранной библиотеки
- Zero‑shot: не требует обучения/датасета; набор классов можно задавать на лету.
- Простая интеграция через `pipeline`, поддержка CPU/GPU.
- Высокое базовое качество благодаря обучению CLIP.

### Принцип работы модели и причины выбора
- CLIP обучает совместное пространство эмбеддингов для изображений и текстовых описаний; сравнение идёт по косинусному сходству.
- Для zero‑shot: текстовые подсказки для классов преобразуются в эмбеддинги, сравниваются с эмбеддингом изображения; максимальное сходство — предсказанный класс.

### Особенности реализации алгоритма
- Инициализация: `pipeline(type='zero-shot-image-classification', model='openai/clip-vit-large-patch14')`.
- Загрузка изображения через `PIL.Image.open`, передача `candidate_labels=["house", "car", "document"]`.
- Сортировка по `score` и выбор лучшего результата; универсально для произвольного списка классов.

### Эффективность
- Для одиночных изображений CPU‑инференс приемлем; GPU ускоряет как извлечение признаков, так и обработку списков классов.
- Стоимость вычислений растёт с размером модели и числом текстовых классов (эмбеддинги текста можно кешировать между вызовами).
- ViT‑L/14 даёт лучшее качество, но выше требования к памяти/времени; для прод‑нагрузок возможны батчирование и более лёгкие модели.
